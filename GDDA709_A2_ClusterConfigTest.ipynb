{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pEgBKctow5c2"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Spark Session with cluster configuration\n",
        "spark = (\n",
        "    SparkSession.builder\n",
        "    .appName(\"ClusterConfigTest\")\n",
        "    .config(\"spark.executor.memory\", \"4g\")  # Set executor memory to 4GB\n",
        "    .config(\"spark.executor.cores\", \"4\")  # Allocate 4 CPU cores per executor\n",
        "    .config(\"spark.driver.memory\", \"2g\")  # Set driver memory to 2GB\n",
        "    .getOrCreate()\n",
        ")"
      ],
      "metadata": {
        "id": "YJwb2P0pxJA5"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display cluster configuration\n",
        "print(\"ðŸ”¹ Spark Configuration:\")\n",
        "for key, value in spark.sparkContext.getConf().getAll():\n",
        "    print(f\"{key}: {value}\")\n",
        "\n",
        "# Stop Spark session\n",
        "spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-0k7D5g0RIG",
        "outputId": "20d05ee7-7a14-4bab-f59d-60ca3112e3da"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”¹ Spark Configuration:\n",
            "spark.driver.extraJavaOptions: -Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false\n",
            "spark.driver.port: 36633\n",
            "spark.executor.memory: 4g\n",
            "spark.driver.host: 8341023a7fbd\n",
            "spark.app.id: local-1738922122217\n",
            "spark.executor.id: driver\n",
            "spark.app.submitTime: 1738922119757\n",
            "spark.executor.cores: 4\n",
            "spark.rdd.compress: True\n",
            "spark.app.name: ClusterConfigTest\n",
            "spark.executor.extraJavaOptions: -Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false\n",
            "spark.driver.memory: 2g\n",
            "spark.serializer.objectStreamReset: 100\n",
            "spark.master: local[*]\n",
            "spark.submit.pyFiles: \n",
            "spark.submit.deployMode: client\n",
            "spark.app.startTime: 1738922120067\n",
            "spark.ui.showConsoleProgress: true\n"
          ]
        }
      ]
    }
  ]
}